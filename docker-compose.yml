services:
  ollama:
    image: ollama/ollama:0.3.13
    ports: ["11434:11434"]
    volumes: ["ollama:/root/.ollama"]
    command: ["serve"]

  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    ports: ["8000:8000"]
    env_file: .env
    environment:
      - LLM_PROVIDER=ollama
      - LLM_MODEL=llama3.2:1b
      - OLLAMA_BASE_URL=http://ollama:11434
    depends_on: [ollama]

  ui:
    build:
      context: .
      dockerfile: Dockerfile.ui
    ports: ["8501:8501"]
    environment:
      - API_BASE_URL=http://localhost:8000
    depends_on: [api]

volumes:
  ollama:
